{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b00765f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:52:53.138670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:53.217928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:53.218178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:52:54.163689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 16:52:54.190134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:54.190495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:54.190701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:54.813533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:54.813790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:54.813982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-15 16:52:54.814154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 804 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 120, 16)           16016     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               12544     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                1560      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,145\n",
      "Trainable params: 30,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:52:59.823852: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.7704\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60292, saving model to saved_models/best_model.h5\n",
      "157/157 [==============================] - 11s 28ms/step - loss: 0.4654 - accuracy: 0.7704 - val_loss: 0.6176 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.4085 - accuracy: 0.8083\n",
      "Epoch 2: val_accuracy improved from 0.60292 to 0.82188, saving model to saved_models/best_model.h5\n",
      "157/157 [==============================] - 4s 25ms/step - loss: 0.4083 - accuracy: 0.8084 - val_loss: 0.3843 - val_accuracy: 0.8219 - lr: 0.0100\n",
      "Epoch 3/25\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.3513 - accuracy: 0.8456\n",
      "Epoch 3: val_accuracy did not improve from 0.82188\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.3515 - accuracy: 0.8456 - val_loss: 0.3764 - val_accuracy: 0.8214 - lr: 0.0100\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8553\n",
      "Epoch 4: val_accuracy improved from 0.82188 to 0.82829, saving model to saved_models/best_model.h5\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.3293 - accuracy: 0.8553 - val_loss: 0.3720 - val_accuracy: 0.8283 - lr: 0.0100\n",
      "Epoch 5/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.8625\n",
      "Epoch 5: val_accuracy did not improve from 0.82829\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.3102 - accuracy: 0.8626 - val_loss: 0.3765 - val_accuracy: 0.8247 - lr: 0.0100\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.8716\n",
      "Epoch 6: val_accuracy did not improve from 0.82829\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.2892 - accuracy: 0.8716 - val_loss: 0.3932 - val_accuracy: 0.8281 - lr: 0.0100\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.8816\n",
      "Epoch 7: val_accuracy did not improve from 0.82829\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.2745 - accuracy: 0.8816 - val_loss: 0.3972 - val_accuracy: 0.8216 - lr: 0.0100\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.8866\n",
      "Epoch 8: val_accuracy did not improve from 0.82829\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.2614 - accuracy: 0.8866 - val_loss: 0.4249 - val_accuracy: 0.8264 - lr: 0.0100\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.8950\n",
      "Epoch 9: val_accuracy did not improve from 0.82829\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.2416 - accuracy: 0.8950 - val_loss: 0.4245 - val_accuracy: 0.8193 - lr: 0.0100\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9142Reached 99% accuracy so cancelling training!\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.82829\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.2005 - accuracy: 0.9142 - val_loss: 0.5073 - val_accuracy: 0.8226 - lr: 1.0000e-03\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "\n",
    "def solution_model():\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy') > 0.9):\n",
    "                print(\"Reached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    #callbacks = myCallback()\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
    "    urllib.request.urlretrieve(url, 'sarcasm.json')\n",
    "\n",
    "    # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n",
    "    vocab_size = 1000\n",
    "    embedding_dim = 16\n",
    "    max_length = 120\n",
    "    trunc_type='post'\n",
    "    padding_type='post'\n",
    "    oov_tok = \"<OOV>\"\n",
    "    training_size = 20000\n",
    "\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "    '''\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpus[0],\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1200)]\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    '''\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(\"Num GPUs:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                      monitor='val_loss')\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                     min_lr=1e-5,\n",
    "                                                     patience=5,\n",
    "                                                     mode='min')\n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_accuracy',\n",
    "                                                          filepath='saved_models/best_model.h5',\n",
    "                                                          save_best_only=True,\n",
    "                                                          verbose=1)\n",
    "    callbacks = [\n",
    "        myCallback(),\n",
    "        #early_stopping,\n",
    "        reduce_lr,\n",
    "        model_checkpoint\n",
    "    ]\n",
    "\n",
    "    with open('sarcasm.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for row in data:\n",
    "            sentences.append(row['headline'])\n",
    "            labels.append(row['is_sarcastic'])\n",
    "\n",
    "    # Prepare data\n",
    "    train_sentences = sentences[:training_size]\n",
    "    valid_sentences = sentences[training_size:]\n",
    "\n",
    "    train_labels = labels[:training_size]\n",
    "    valid_labels = labels[training_size:]\n",
    "\n",
    "    # Prepare input\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size,\n",
    "                                                      oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "    train_seqs = tokenizer.texts_to_sequences(train_sentences)\n",
    "    train_pad_seqs = tf.keras.preprocessing.sequence.pad_sequences(train_seqs,\n",
    "                                                                   maxlen=max_length,\n",
    "                                                                   padding=padding_type,\n",
    "                                                                   truncating=trunc_type)\n",
    "    valid_seqs = tokenizer.texts_to_sequences(valid_sentences)\n",
    "    valid_pad_seqs = tf.keras.preprocessing.sequence.pad_sequences(valid_seqs,\n",
    "                                                                   maxlen=max_length,\n",
    "                                                                   padding=padding_type,\n",
    "                                                                   truncating=trunc_type)\n",
    "\n",
    "    train_labels = np.array(train_labels)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "\n",
    "    # Training\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                  output_dim=embedding_dim,\n",
    "                                  input_length=max_length,\n",
    "                                  #weights=[embeddings_matrix],\n",
    "                                  trainable=True),\n",
    "\n",
    "        # tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        # tf.keras.layers.SpatialDropout1D(0.2),\n",
    "        # tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        # tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "\n",
    "        # tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        # tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "\n",
    "        # tf.keras.layers.Dropout(0.2),\n",
    "        # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        # tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "        # YOUR CODE HERE. KEEP THIS OUTPUT LAYER INTACT OR TESTS MAY FAIL\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=train_pad_seqs,\n",
    "              y=train_labels,\n",
    "              validation_data=(valid_pad_seqs, valid_labels),\n",
    "              batch_size=128,\n",
    "              shuffle=True,\n",
    "              epochs=25,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"saved_models/examQ4.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d859a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
